{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "882e7163-7585-40eb-bba9-ebafbc78aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import xarray as xr\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from glob import glob\n",
    "from datetime import datetime, timezone\n",
    "from zoneinfo import ZoneInfo # Python 3.9\n",
    "import pytz\n",
    "from multiprocess import Pool\n",
    "from tqdm import tqdm\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96c31d8-a0e0-4915-911b-24a0218af538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "## my own directory\n",
    "os.chdir(\"/g/data/k10/dl6968/Semi-variogram_AU/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29f61281-05b0-46aa-b61b-9710b0e9cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177c0a44-4d3b-4cc0-9270-41aaab66eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon_tz(lat,lon):\n",
    "    tz = tzwhere.tzwhere()\n",
    "    timezone_str = tz.tzNameAt(lat, lon,forceTZ=True) \n",
    "    LocalZone = ZoneInfo(timezone_str)\n",
    "    return LocalZone\n",
    "\n",
    "def local_to_utc(local_time, local_tz, dt_format = \"%Y%m%d %H:%M\"):\n",
    "    ## first convert strings to datetime\n",
    "    Local = [datetime.strptime(s, dt_format).replace(tzinfo=local_tz) for s in local_time]\n",
    "    UTC = [dt.astimezone(timezone.utc) for dt in Local]\n",
    "    return UTC\n",
    "\n",
    "def find_aus_tz(state):\n",
    "    state = state.replace(\" \", \"\")\n",
    "    if state==\"WA\" or state==\"Western Australia\":\n",
    "        tz_string = \"Australia/West\"\n",
    "    elif state==\"SA\" or state==\"South Australia\":\n",
    "        tz_string = \"Australia/South\"\n",
    "    elif state == \"VIC\" or state==\"Victoria\":\n",
    "        tz_string = \"Australia/Victoria\"\n",
    "    elif state == \"TAS\" or state==\"Tasmania\":\n",
    "        tz_string = \"Australia/Tasmania\" \n",
    "    elif state == \"ANT\" or state==\"Antarctica\":\n",
    "        tz_string = \"Antarctica/McMurdo\"  \n",
    "    elif state == \"NSW\" or state==\"New South Wales\" or state==\"Australian Capital Territory\" or state==\"ACT\":\n",
    "        tz_string = \"Australia/NSW\"\n",
    "    elif state == \"QLD\" or state==\"Queensland\":\n",
    "        tz_string = \"Australia/Queensland\"\n",
    "    elif state == \"NT\" or state==\"Northern Territory\":\n",
    "        tz_string = \"Australia/North\"\n",
    "    else:\n",
    "        print(\"wrong state\")\n",
    "    LocalZone = ZoneInfo(tz_string)\n",
    "    return LocalZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32b72971-ff88-41d1-a980-4194d48f9408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lat_lon_state(latitude, longitude):\n",
    "    # Initialize geolocator with user agent\n",
    "    geolocator = Nominatim(user_agent=\"geoapi\")\n",
    "    \n",
    "    # Perform reverse geocoding\n",
    "    location = geolocator.reverse((latitude, longitude), exactly_one=True)\n",
    "    \n",
    "    # Extract state and state code\n",
    "    if location:\n",
    "        address = location.raw['address']\n",
    "        state = address.get('state', '')\n",
    "        if len(state)==0:\n",
    "            state = address.get('territory', '')\n",
    "    else:\n",
    "        print(\"Location not found\")\n",
    "        return \"NaN\"\n",
    "    \n",
    "    state_mapping = {\n",
    "        'New South Wales': 'NSW',\n",
    "        'Victoria': 'VIC',\n",
    "        'Queensland': 'QLD',\n",
    "        'South Australia': 'SA',\n",
    "        'Western Australia': 'WA',\n",
    "        'Tasmania': 'TAS',\n",
    "        'Northern Territory': 'NT',\n",
    "        'Australian Capital Territory': 'ACT'\n",
    "    }\n",
    "    \n",
    "    # Get the state code using the mapping\n",
    "    state_code = state_mapping.get(state, '')\n",
    "    return state_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c88f939-31c1-4764-b669-557efa44982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f\"/g/data/w40/dl6968/BoM_daily_stations/all/csv/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3499bf8e-2633-40da-9d2d-b335b1c9aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notes = pd.read_csv(\"./data/BoM_daily_stations_state.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfbcc713-2d37-4c59-8315-f2b508477eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qflag_mapping = {\n",
    "    \"Y\" : 0,\n",
    "    \"N\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e629bad1-8521-48da-a479-06f8e9df2001",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def txt_to_nc(file):\n",
    "    data_header = [\"product_code\", \"Station_Number\", \"Year\", \"Month\", \"Day\", \"Rainfall\", \"Period\", \"Quality\"]\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        flag = 1\n",
    "    except:\n",
    "        print(\"check file: \"+file)\n",
    "        return None\n",
    "    if flag==1:\n",
    "        df = df.rename(columns=dict(zip(df, data_header)))\n",
    "        station_id = file[-20:-14]\n",
    "        out_file = f\"/g/data/w40/dl6968/BoM_daily_stations/netcdf/{station_id}.nc\"\n",
    "        \n",
    "        df[\"local_time\"] = (\n",
    "                    df[\"Year\"].astype(str)\n",
    "                    + df[\"Month\"].astype(str).str.zfill(2)\n",
    "                    + df[\"Day\"].astype(str).str.zfill(2)\n",
    "                    + \" \"\n",
    "                    + \"09\"\n",
    "                    + \":\"\n",
    "                    + \"00\"\n",
    "                )\n",
    "        lat = df_notes.loc[df_notes[\"ID\"]==int(station_id),\"Latitude\"].values[0]\n",
    "        lon = df_notes.loc[df_notes[\"ID\"]==int(station_id),\"Longitude\"].values[0]\n",
    "        state = str(df_notes.loc[df_notes[\"ID\"]==int(station_id),\"State\"].values[0])\n",
    "        state_note = \"\"\n",
    "        if state==\"nan\":\n",
    "            state_note = \"No state forced to QLD\"\n",
    "            state = \"QLD\"\n",
    "        local_tz = find_aus_tz(state)\n",
    "        local_time = df[\"local_time\"].tolist()\n",
    "        utc_time = local_to_utc(local_time, local_tz)\n",
    "        out_time = [np.datetime64(utc_ts) for utc_ts in utc_time]\n",
    "        df[\"quality_int\"] = df[\"Quality\"].map(qflag_mapping)\n",
    "        ## time lapse\n",
    "        ## precipitation data\n",
    "        lapse = []\n",
    "        for days in df[\"Period\"].values:\n",
    "            try:\n",
    "                lapse.append(float(days))\n",
    "            except:\n",
    "                lapse.append(np.nan)\n",
    "        \n",
    "        prcp = []\n",
    "        for rain in df[\"Rainfall\"].values:\n",
    "            try:\n",
    "                prcp.append(float(rain))\n",
    "            except:\n",
    "                prcp.append(np.nan)\n",
    "        \n",
    "        \n",
    "        \n",
    "        nc_output = xr.Dataset()\n",
    "        for keys in df_notes.keys():\n",
    "            nc_output.attrs[keys] = df_notes[keys].loc[df_notes[\"ID\"]==float(station_id)].values[0]\n",
    "        nc_output.attrs[\"State\"] = state\n",
    "        nc_output.attrs[\"State_note\"] = state_note\n",
    "        nc_output.attrs[\"Station_Number\"] = station_id\n",
    "        nc_output.attrs['author'] = 'Dongqi Lin (dongqi.lin@monash.edu)'\n",
    "        \n",
    "        nc_output['time'] = xr.DataArray(np.array(out_time), dims=['time'])\n",
    "        nc_output['time'].encoding['units'] = \"seconds since 1970-01-01 00:00:00\"\n",
    "        nc_output['time'].encoding['calendar'] = \"proleptic_gregorian\"\n",
    "        nc_output['time'].attrs[\"notes\"] = \"UTC time\"\n",
    "        nc_output['prcp'] = xr.DataArray(np.array(prcp), dims=['time'],\n",
    "                 attrs={'description':'Precipitation since last AWS observation','units':\"mm\"})\n",
    "        nc_output['local_time'] = xr.DataArray(local_time, dims=['time'],\n",
    "                 attrs={'description':'Local time','units':\"\"})\n",
    "        \n",
    "        nc_output['Time_lapse'] = xr.DataArray(np.array(lapse), dims=['time'],\n",
    "                 attrs={'description':'Period over which precipitation since last (AWS) observation is measured in days',\n",
    "                        'units':\"minutes\"})\n",
    "        \n",
    "        nc_output['quality_flag'] = xr.DataArray(df[\"quality_int\"].values, dims=['time'],\n",
    "                 attrs={'description':'Quality flag: Y-0, N-1',\n",
    "                        'Y': 'quality controlled',\n",
    "                        'N': 'could be wrong if additionall quality control is done in future',\n",
    "                        'units':\"\"})\n",
    "        nc_output.to_netcdf(out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d22e0629-1783-457e-a476-10282e48910b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 350/17830 [00:10<05:59, 48.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check file: /g/data/w40/dl6968/BoM_daily_stations/all/csv/IDCJAC0009_035285_1800_Data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 16449/17830 [05:45<00:31, 43.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check file: /g/data/w40/dl6968/BoM_daily_stations/all/csv/IDCJAC0009_040780_1800_Data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17830/17830 [06:14<00:00, 47.56it/s]\n"
     ]
    }
   ],
   "source": [
    "# use multiprocess  \n",
    "# max_pool means maximum CPU to use\n",
    "max_pool = 20\n",
    "\n",
    "with Pool(max_pool) as p:\n",
    "    pool_outputs = list(\n",
    "        tqdm(\n",
    "            p.imap(txt_to_nc,\n",
    "                   files),\n",
    "            total=len(files),\n",
    "            position=0, leave=True\n",
    "        )\n",
    "    )\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254c70b6-49fc-4a67-b0ee-25dd78147bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
