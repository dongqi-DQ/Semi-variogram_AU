{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da1ba636-485e-4743-8d7c-70f48e5c90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic \n",
    "import math\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "from multiprocess import Pool\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f030a21e-d1c5-438e-8ee6-e507c379d92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gstools import CovModel\n",
    "\n",
    "class Stab(CovModel):\n",
    "    def variogram(self, r):\n",
    "        \n",
    "        return self.nugget + self.sill * (1 - np.exp(-(3 * r) / self.len_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "793275fe-d140-423f-ab2f-93dc6016daeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the piecewise function\n",
    "def custom_curve(h, c, b, alpha):\n",
    "    if np.isscalar(h):\n",
    "        # Handle the scalar case\n",
    "        if h == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return c + b * (1 - np.exp(-3 * h / alpha))\n",
    "    else:\n",
    "        # Handle array inputs\n",
    "        return np.where(h == 0, 0, c + b * (1 - np.exp(-3 * h / alpha)))\n",
    "\n",
    "def fit_sci_curve(h_values, y_values,bins):\n",
    "\n",
    "    # Use curve_fit to fit the custom function to the data\n",
    "    # Initial guess for c, b, and alpha\n",
    "    initial_guess = [0, 0.5, 5]  \n",
    "    \n",
    "    # Perform the curve fitting\n",
    "    params, covariance = curve_fit(custom_curve, h_values, y_values, p0=initial_guess)\n",
    "    \n",
    "    # Extract the fitted parameters\n",
    "    c_fitted, b_fitted, alpha_fitted = params\n",
    "    \n",
    "    y_fit = custom_curve(bins, c_fitted, b_fitted, alpha_fitted)\n",
    "    return y_fit, alpha_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d34c82ab-e0d0-45a7-9dce-432a1406cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ratio_gamma(N11,N10):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "        ratio = np.where(N10 + N11 != 0, 0.5 * (N10 / (N10 + N11)), np.nan)\n",
    "        # if len(ratio.shape)==2:\n",
    "        #     ratio[:,0] = 0\n",
    "        # if len(ratio.shape)==1:\n",
    "        #     ratio[0] = 0    \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4510116d-bfa0-4d9d-a012-249165b6ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define distance bins\n",
    "bins = np.arange(5, 360, 10)\n",
    "\n",
    "# Function to get pairwise distances\n",
    "# including the station at the centre\n",
    "def get_pairwise_distances(df):\n",
    "    spec_stn = df[\"Spec_stn\"].iloc[0]\n",
    "    stn_list = df[\"Neighb_stn\"].values\n",
    "    stn_list = np.append(spec_stn, stn_list)\n",
    "    stn_str = [str(ids) for ids in stn_list]\n",
    "    distances =  df_dist.loc[stn_list, stn_str].values\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Function to calculate N11 and N10 pairs\n",
    "def calculate_pairs(df, bins):\n",
    "    distances = get_pairwise_distances(df)\n",
    "    n = len(df) + 1  # Include the station at the neighborhood center\n",
    "    extreme = np.append(90, df['flag'].values)  # Append the center station's flag\n",
    "\n",
    "    # Initialize arrays for N11 and N10\n",
    "    N11 = np.zeros_like(bins, dtype=int)\n",
    "    N10 = np.zeros_like(bins, dtype=int)\n",
    "\n",
    "    # Precompute bin indices for all pairs\n",
    "    bin_indices = np.digitize(distances, bins) - 1\n",
    "\n",
    "    # Create masks for valid bin indices\n",
    "    valid_mask = (bin_indices >= 0) & (bin_indices < len(bins))\n",
    "\n",
    "    # Create masks for 1-1 and 1-0 pairs\n",
    "    mask_11 = (extreme[:, None] > 0) & (extreme[None, :] > 0)  # 1-1 pairs\n",
    "    mask_10 = ((extreme[:, None] > 0) & (extreme[None, :] == 0)) | ((extreme[:, None] == 0) & (extreme[None, :] > 0))  # 1-0 pairs\n",
    "\n",
    "    # Iterate over all bins\n",
    "    for bin_idx in range(len(bins)):\n",
    "        # Find pairs that fall into this bin\n",
    "        bin_mask = (bin_indices == bin_idx) & valid_mask\n",
    "\n",
    "        # Count 1-1 and 1-0 pairs in this bin\n",
    "        N11[bin_idx] = np.sum(mask_11 & bin_mask)\n",
    "        N10[bin_idx] = np.sum(mask_10 & bin_mask)\n",
    "\n",
    "    return N11/2, N10/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95480038-38e5-45d4-884d-fd395cd1a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_alpha(gamma_fit,bins_fit,bins):\n",
    "    # gamma_fit = gamma[~np.isnan(gamma)]\n",
    "    # bins_fit = bins[~np.isnan(bins)]\n",
    "    y_fit = 0\n",
    "    scale = 0\n",
    "    try:\n",
    "        _ = fit_model.fit_variogram(bins_fit, gamma_fit,  nugget=0, sill=0.5)#)#\n",
    "        y_fit = fit_model.variogram(bins)\n",
    "        scale = fit_model.len_scale\n",
    "    except RuntimeError:\n",
    "        try: \n",
    "            ## adjust the cape a little bit so the code can pass through\n",
    "            _ = fit_model.fit_variogram(bins_fit, gamma_fit,  nugget=0, sill=0.51)#)#\n",
    "            y_fit = fit_model.variogram(bins)\n",
    "            scale = fit_model.len_scale\n",
    "        except RuntimeError:\n",
    "            y_fit,alpha = fit_sci_curve(bins_fit,gamma_fit,bins)\n",
    "            # no_fit_days.append(days)\n",
    "            scale = alpha\n",
    "    return y_fit, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231439e8-ed65-4c95-a4c2-438be73b3e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_pair_alpha(days):\n",
    "    df = df_stations_p90[df_stations_p90[\"Day\"]==days]\n",
    "    if df[\"flag\"].max() <=0:\n",
    "        N11 = np.zeros_like(bins)\n",
    "        N10 = np.zeros_like(bins)\n",
    "        gamma = np.zeros_like(bins)\n",
    "        y_fit = np.zeros_like(bins)\n",
    "        scale = 0\n",
    "    else:\n",
    "        \n",
    "        # Calculate N11 and N10 pairs\n",
    "        N11, N10 = calculate_pairs(df, bins)\n",
    "        gamma = calc_ratio_gamma(N11, N10)        \n",
    "        gamma_fit = gamma.copy()\n",
    "        bins_fit = bins.copy().astype(float)\n",
    "        gamma_fit[N11+N10<=2] = np.nan\n",
    "        bins_fit[N11+N10<=2] = np.nan\n",
    "        ## make sure start with zeros\n",
    "        # gamma_fit[0] = 0\n",
    "        # bins_fit[0] =0\n",
    "        ## remove NaNs \n",
    "        gamma_fit1 = gamma_fit[~np.isnan(gamma_fit)]\n",
    "        bins_fit1 = bins_fit[~np.isnan(bins_fit)]\n",
    "        ## in case all NaNs occured\n",
    "        if len(gamma_fit1)<=2:\n",
    "            y_fit = np.zeros_like(bins)\n",
    "            scale = 0\n",
    "        else:\n",
    "            y_fit, scale = calc_alpha(gamma_fit1, bins_fit1, bins)\n",
    "    local_bins_dict = {\n",
    "        \"Day\": [days] * len(bins),\n",
    "        \"Date\": [df_stations_p90[\"Date\"][df_stations_p90[\"Day\"]==days].values[0]] *len(bins),\n",
    "        \"Bins\": bins.tolist(),\n",
    "        \"N11\": N11.tolist(),\n",
    "        \"N10\": N10.tolist(),\n",
    "        \"gamma\": gamma.tolist(),\n",
    "        \"y_fit\": y_fit.tolist()\n",
    "    }\n",
    "    return local_bins_dict, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6cdd52-ee6a-4c15-9893-60658929b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## my own directory\n",
    "os.chdir(\"/g/data/k10/dl6968/Semi-variogram_AU/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26e86845-06b1-47d7-b475-5e6e886d031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = Stab(dim=2)#gs.Stable(dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77acb86-72ef-4977-b576-1722d34faac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 27s, sys: 6.78 s, total: 2min 34s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_dist = pd.read_csv(\"./data/pairwise_distances.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c8f1c44-2ac0-4dc4-b351-43607a644432",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(glob(\"./data/all_AU_p90/*_station_list_all_events.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1542454b-ba67-4081-b04f-95bb09361548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9841/9841 [1:57:03<00:00,  1.40it/s]  \n"
     ]
    }
   ],
   "source": [
    "max_pool = 28\n",
    "for file in tqdm(files, leave=True, position=0, total=len(files)):\n",
    "    if not os.path.exists(file.replace(\"station\",\"pair_scale\")):\n",
    "        df_stations_p90 = pd.read_csv(file)\n",
    "        with Pool(max_pool) as p:\n",
    "            pool_outputs = list(\n",
    "                    p.imap(calc_pair_alpha,\n",
    "                           np.unique(df_stations_p90[\"Day\"])),\n",
    "            )\n",
    "        p.join()\n",
    "        \n",
    "        y_fit_arr = np.zeros((len(np.unique(df_stations_p90[\"Day\"])), bins.shape[0]))\n",
    "        N11_arr = np.zeros_like(y_fit_arr)\n",
    "        N10_arr = np.zeros_like(y_fit_arr)\n",
    "        gamma_arr = np.zeros_like(y_fit_arr)\n",
    "        scale_arr = np.zeros(len(np.unique(df_stations_p90[\"Day\"])))\n",
    "        bins_dict = {\"Day\": [], \"Date\": [], \"Bins\": [], \"N11\": [], \"N10\": [], \"gamma\": [], \"y_fit\": []}\n",
    "        for i in range(0, len(np.unique(df_stations_p90[\"Day\"]))):\n",
    "            scale_arr[i] = pool_outputs[i][1]\n",
    "            for key in bins_dict:\n",
    "                    bins_dict[key].extend(pool_outputs[i][0][key])\n",
    "            \n",
    "        scale_dict = {\"extreme_dates\": np.unique(df_stations_p90[\"Date\"]), \"scale\": scale_arr}\n",
    "        df_scale = pd.DataFrame.from_dict(scale_dict)\n",
    "        df_scale.to_csv(file.replace(\"station\",\"pair_scale\"))\n",
    "        \n",
    "        df_bins =  pd.DataFrame.from_dict(bins_dict)\n",
    "        df_bins.to_csv(file.replace(\"station\",\"pair_bins\"))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87f444-df46-4bd8-9378-c01697cb3f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
